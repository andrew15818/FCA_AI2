{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg4ieOBos5pP",
        "colab_type": "text"
      },
      "source": [
        "# Number Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcqj2T_osuCc",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JduqNTZsaLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7caEzhEJs2DN",
        "colab_type": "text"
      },
      "source": [
        "## Loading Image Data\n",
        "TODO: \n",
        "- Load the image data\n",
        "- Reshape the matrices\n",
        "- Turn the y data into class categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o1a4qwuvtNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset():\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  print(f'Using {x_train.shape[0]} training data.')\n",
        "  print(f'Using {x_test.shape[0]} testing data.')\n",
        "  \n",
        "  # Reshape the images\n",
        "  x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "  x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
        "\n",
        "  # Turn the y lists into class categories\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbBVL_SCks-2",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the images\n",
        "Turn the images into floating point numbers (decimals) and \"normalize\" them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OrM4kOQk2aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_images(train, test):\n",
        "  # Convert the integers to decimals\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = train.astype('float32')\n",
        "\n",
        "  # Make the numbers go between 0-1\n",
        "  train_norm /= 255.0\n",
        "  test_norm  /= 255.0\n",
        "\n",
        "  return train_norm, test_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXsi-xayoDv_",
        "colab_type": "text"
      },
      "source": [
        "## Create our model\n",
        "We create our model layer by layer. Our network structure is as follows:\n",
        "1. **Convolutional Layer**: This will take a region of our image and \"simplify it\", decreasing the amount of data but still keeping important features.\n",
        "2. **Max-Pooling layer** These layers will help us simplify our feature maps even more.\n",
        "3. **Dense Layer**: Like in traditional neural networks, these layers connect to all the neurons in the next layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgFUWYkCqe5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # compile our model\n",
        "  opt = SGD(lr=0.01, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGVMOh5MuYZ7",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the model\n",
        "To see how our model is performing, we use a small part of our training set as a small \"test set\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK-DFTphuu02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def evaluate_model(x_data, y_data, n_folds=5):\n",
        "  scores, histories = [], []\n",
        "  kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "  for train_ix, test_ix in kfold.split(x_data):\n",
        "    model = create_model()\n",
        "    model.summary()\n",
        "    # Get our training dataset\n",
        "    x_train, y_train  = x_data[train_ix], y_data[train_ix]\n",
        "\n",
        "    # Get our testing data set\n",
        "    x_test, y_test = x_data[test_ix], y_data[test_ix] \n",
        "    print(f'Shapes: {x_train.shape}\\t{x_test.shape}')\n",
        "    # Pass our data along our model\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "    # evaluate our model\n",
        "    _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "    return scores, histories\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZEe2s9a0FoE",
        "colab_type": "text"
      },
      "source": [
        "## Summarize model's preformance\n",
        "Here we make a graph with the accuracies of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBJ80_TF0SFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_model_performance(histories):\n",
        "  for i in range(histories):\n",
        "    plt.subplot(2, 1, 1)\n",
        "    pyplot.title('Error')\n",
        "    pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "    # plot the accuracy\n",
        "    pyplot.subplot(2, 1, 2)\n",
        "    pyplot.title('Model Accuracy')\n",
        "    pyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtpBmE831wmN",
        "colab_type": "text"
      },
      "source": [
        "## Main function\n",
        "Here is where our program starts executing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YnV_twr122M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a781a0b8-1b6d-4c14-e1cc-10998ce0350a"
      },
      "source": [
        "def main():\n",
        "  # Load the dataset\n",
        "  x_train, y_train, x_test, y_test = load_dataset()\n",
        "  x_train, x_test = prep_images(x_train, x_test)\n",
        "  # Evaluate our model\n",
        "  scores, histories = evaluate_model(x_train, y_train)\n",
        "  # Make a graph with our model's performance\n",
        "  plot_model_performance(histories)\n",
        "\n",
        "  # Print our model's performance\n",
        "  print('Accuracy: mea = %.3f, images = %.3f' % (np.mean(scores)*100, len(scores)))\n",
        "  \n",
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 60000 training data.\n",
            "Using 10000 testing data.\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 100)               540900    \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 542,758\n",
            "Trainable params: 542,494\n",
            "Non-trainable params: 264\n",
            "_________________________________________________________________\n",
            "Shapes: (48000, 28, 28, 1)\t(12000, 28, 28, 1)\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.1354 - accuracy: 0.9589 - val_loss: 0.0742 - val_accuracy: 0.9783\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.0673 - val_accuracy: 0.9803\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0323 - accuracy: 0.9901 - val_loss: 0.0631 - val_accuracy: 0.9807\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0549 - val_accuracy: 0.9846\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0564 - val_accuracy: 0.9841\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0522 - val_accuracy: 0.9862\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 41s 28ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0543 - val_accuracy: 0.9855\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0565 - val_accuracy: 0.9860\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 40s 27ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0566 - val_accuracy: 0.9862\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 41s 27ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0592 - val_accuracy: 0.9852\n",
            "> 98.525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-175-678e1f05367f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-175-678e1f05367f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Make a graph with our model's performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mplot_model_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Print our model's performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-174-2be5d89bc14c>\u001b[0m in \u001b[0;36mplot_model_performance\u001b[0;34m(histories)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_model_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He0TobErOXXp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNx7z-3XXY_e",
        "colab_type": "text"
      },
      "source": [
        "## Sample pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDe3ijgFXjjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Sample')\n",
        "plt.imshow(x_train[0], cmap=pyplot.get_cmap('gray'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}